## 问题分析

### 1. **并行化材质排序键计算的竞态条件**

```cpp
// 在 FlushRenderQueue 中
for (size_t j = i; j < endIdx; ++j) {
    auto* renderable = dirtyRenderables[j];
    // ⚠️ 问题：多线程同时调用 EnsureMaterialSortKey
    EnsureMaterialSortKey(renderable, layerDepthFunc);
}
```

**问题点：**
- `EnsureMaterialSortKey` 会调用 `renderable->SetMaterialSortKey(key)`
- 如果 `Renderable` 对象的 `SetMaterialSortKey` 不是线程安全的，会导致数据竞争
- `BuildModelRenderableSortKey` 调用 `modelRenderable->SetTransparentHint(transparent)` 也存在竞态

### 2. **并行化层级排序的潜在问题**

```cpp
auto handle = TaskScheduler::GetInstance().SubmitLambda(
    [this, sortTask]() {
        SortLayerItems(sortTask.bucket->items, *sortTask.descriptor);
    },
    // ⚠️ 问题：多线程访问同一个 bucket->items
);
```

**问题点：**
- 虽然每个 bucket 独立排序，但如果 `LayerItem` 或 `Renderable` 有共享状态，仍可能有问题
- `SortLayerItems` 中调用 `resolveKey()` 可能触发 `BuildFallbackMaterialKey`

### 3. **共享状态访问问题**

```cpp
// Logger 和全局状态
Logger::GetInstance().DebugFormat(...);  // 可能不是线程安全的
MaterialStateCache::Get().Reset();        // 全局单例访问
```

## 修复方案
```
// ============================================================================
// 方案1：修复并行化实现（推荐）
// ============================================================================

// 在 Renderable 类中添加线程安全的方法（需要在 renderable.h 中添加）
class Renderable {
private:
    mutable std::mutex m_materialSortKeyMutex;
    MaterialSortKey m_materialSortKey;
    std::atomic<bool> m_materialSortKeyDirty{true};
    std::atomic<bool> m_hasMaterialSortKey{false};
    std::atomic<bool> m_transparentHint{false};
    
public:
    // 线程安全的设置方法
    void SetMaterialSortKeyThreadSafe(const MaterialSortKey& key) {
        std::lock_guard<std::mutex> lock(m_materialSortKeyMutex);
        m_materialSortKey = key;
        m_hasMaterialSortKey.store(true, std::memory_order_release);
        m_materialSortKeyDirty.store(false, std::memory_order_release);
    }
    
    // 线程安全的获取方法
    MaterialSortKey GetMaterialSortKeyThreadSafe() const {
        std::lock_guard<std::mutex> lock(m_materialSortKeyMutex);
        return m_materialSortKey;
    }
    
    // 线程安全的透明度提示设置
    void SetTransparentHintThreadSafe(bool transparent) {
        m_transparentHint.store(transparent, std::memory_order_release);
    }
    
    bool GetTransparentHint() const {
        return m_transparentHint.load(std::memory_order_acquire);
    }
};

// 修改 EnsureMaterialSortKey 以使用线程安全方法
void EnsureMaterialSortKeyThreadSafe(Renderable* renderable, 
                                      std::optional<DepthFunc> layerDepthFunc = std::nullopt) {
    if (!renderable) {
        return;
    }

    // 使用原子操作检查
    if (renderable->HasMaterialSortKey() && !renderable->IsMaterialSortKeyDirty()) {
        return;
    }

    MaterialSortKey key{};
    bool computed = false;

    switch (renderable->GetType()) {
        case RenderableType::Mesh: {
            auto* meshRenderable = static_cast<MeshRenderable*>(renderable);
            key = BuildMeshRenderableSortKey(meshRenderable, layerDepthFunc);
            computed = true;
            break;
        }
        case RenderableType::Model: {
            auto* modelRenderable = static_cast<ModelRenderable*>(renderable);
            key = BuildModelRenderableSortKeyThreadSafe(modelRenderable, layerDepthFunc);
            computed = true;
            break;
        }
        case RenderableType::Sprite: {
            auto* spriteRenderable = static_cast<SpriteRenderable*>(renderable);
            key = BuildSpriteRenderableSortKey(spriteRenderable, layerDepthFunc);
            computed = true;
            break;
        }
        case RenderableType::Text: {
            auto* textRenderable = static_cast<TextRenderable*>(renderable);
            key = BuildTextRenderableSortKey(textRenderable, layerDepthFunc);
            computed = true;
            break;
        }
        default:
            break;
    }

    if (computed) {
        renderable->SetMaterialSortKeyThreadSafe(key);
    }
}

// 修改 BuildModelRenderableSortKey 以使用线程安全方法
MaterialSortKey BuildModelRenderableSortKeyThreadSafe(
    ModelRenderable* modelRenderable, 
    std::optional<DepthFunc> layerDepthFunc = std::nullopt) {
    
    MaterialSortKey key{};
    if (!modelRenderable) {
        return key;
    }

    ModelPtr model = modelRenderable->GetModel();
    if (!model) {
        return key;
    }

    uint32_t overrideHash = 0;
    uint32_t pipelineFlags = MaterialPipelineFlags_None;
    Material* primaryMaterial = nullptr;
    bool anyBlend = false;
    BlendMode resolvedBlend = BlendMode::None;
    bool transparent = false;

    // Model::AccessParts 需要是线程安全的（只读访问）
    model->AccessParts([&](const std::vector<ModelPart>& parts) {
        for (const auto& part : parts) {
            if (part.castShadows) {
                pipelineFlags |= MaterialPipelineFlags_CastShadow;
            }
            if (part.receiveShadows) {
                pipelineFlags |= MaterialPipelineFlags_ReceiveShadow;
            }

            if (!part.material) {
                continue;
            }

            if (!primaryMaterial) {
                primaryMaterial = part.material.get();
            }

            overrideHash = HashCombine(overrideHash, HashPointer(part.material.get()));
            overrideHash = HashCombine(overrideHash, HashFloat(part.material->GetOpacity()));

            if (auto shader = part.material->GetShader()) {
                overrideHash = HashCombine(overrideHash, HashPointer(shader.get()));
            }

            const BlendMode blend = part.material->GetBlendMode();
            if (!anyBlend) {
                resolvedBlend = blend;
                anyBlend = true;
            } else if (resolvedBlend != blend) {
                resolvedBlend = BlendMode::Custom;
            }

            if (blend == BlendMode::Alpha || blend == BlendMode::Additive || 
                part.material->GetOpacity() < 1.0f) {
                transparent = true;
            }
        }
    });

    key = BuildMaterialSortKey(primaryMaterial, overrideHash, pipelineFlags, layerDepthFunc);
    key.materialID = overrideHash;
    if (anyBlend) {
        key.blendMode = resolvedBlend;
    }

    // 使用线程安全方法
    modelRenderable->SetTransparentHintThreadSafe(transparent);

    return key;
}

// 修改后的并行化材质键计算
void Renderer::FlushRenderQueue_ParallelFixed() {
    // ... 前面的代码保持不变 ...
    
    // 收集需要计算排序键的对象
    std::vector<Renderable*> dirtyRenderables;
    dirtyRenderables.reserve(originalQueue.size());
    for (auto* renderable : originalQueue) {
        if (renderable && renderable->IsMaterialSortKeyDirty()) {
            dirtyRenderables.push_back(renderable);
        }
    }
    
    // 构建layerID到depthFunc的映射
    std::unordered_map<uint32_t, std::optional<DepthFunc>> layerDepthFuncMap;
    for (const auto& record : layerRecords) {
        layerDepthFuncMap[record.descriptor.id.value] = record.state.overrides.depthFunc;
    }
    
    // 并行计算排序键
    const size_t minDirtyForParallel = 100;
    if (!dirtyRenderables.empty() && 
        dirtyRenderables.size() >= minDirtyForParallel &&
        TaskScheduler::GetInstance().IsInitialized()) {
        
        const size_t numThreads = TaskScheduler::GetInstance().GetWorkerCount();
        const size_t itemsPerTask = std::max(size_t(50), dirtyRenderables.size() / numThreads);
        
        std::vector<std::shared_ptr<TaskHandle>> sortKeyHandles;
        
        for (size_t i = 0; i < dirtyRenderables.size(); i += itemsPerTask) {
            const size_t endIdx = std::min(i + itemsPerTask, dirtyRenderables.size());
            
            // ✅ 捕获必要的数据副本，避免引用悬挂
            auto handle = TaskScheduler::GetInstance().SubmitLambda(
                [dirtyRenderables, layerDepthFuncMap, i, endIdx]() {
                    for (size_t j = i; j < endIdx; ++j) {
                        auto* renderable = dirtyRenderables[j];
                        std::optional<DepthFunc> layerDepthFunc = std::nullopt;
                        auto it = layerDepthFuncMap.find(renderable->GetLayerID());
                        if (it != layerDepthFuncMap.end()) {
                            layerDepthFunc = it->second;
                        }
                        // ✅ 使用线程安全版本
                        EnsureMaterialSortKeyThreadSafe(renderable, layerDepthFunc);
                    }
                },
                TaskPriority::High,
                "SortKeyCalc"
            );
            sortKeyHandles.push_back(handle);
        }
        
        // 等待所有排序键计算完成
        TaskScheduler::GetInstance().WaitForAll(sortKeyHandles);
    } else {
        // 少量dirty或TaskScheduler未初始化，串行计算
        for (auto* renderable : dirtyRenderables) {
            std::optional<DepthFunc> layerDepthFunc = std::nullopt;
            auto it = layerDepthFuncMap.find(renderable->GetLayerID());
            if (it != layerDepthFuncMap.end()) {
                layerDepthFunc = it->second;
            }
            EnsureMaterialSortKeyThreadSafe(renderable, layerDepthFunc);
        }
    }
    
    // ... 后续代码保持不变 ...
}

// 修改后的并行化层级排序
void Renderer::FlushRenderQueue_LayerSortFixed() {
    // ... 前面的代码保持不变 ...
    
    struct SortTask {
        LayerBucket* bucket;
        RenderLayerDescriptor descriptor;  // ✅ 存储副本而非指针
    };
    std::vector<SortTask> sortTasks;
    sortTasks.reserve(layerRecords.size());
    
    for (const auto& record : layerRecords) {
        auto lookupIt = snapshotLookup.find(record.descriptor.id.value);
        if (lookupIt == snapshotLookup.end()) {
            continue;
        }

        const size_t bucketIndex = lookupIt->second;
        if (bucketIndex >= bucketsSnapshot.size()) {
            continue;
        }

        LayerBucket& bucket = bucketsSnapshot[bucketIndex];
        
        if (bucket.items.empty()) {
            continue;
        }
        
        const bool maskAllows =
            (record.descriptor.maskIndex >= 32) ||
            ((activeLayerMask >> record.descriptor.maskIndex) & 0x1u);
        
        if (!record.state.enabled || !maskAllows) {
            continue;
        }
        
        // ✅ 存储 descriptor 的副本
        sortTasks.push_back(SortTask{&bucket, record.descriptor});
    }
    
    // 并行排序所有层级
    const size_t minItemsForParallel = 100;
    if (!sortTasks.empty() && TaskScheduler::GetInstance().IsInitialized()) {
        std::vector<std::shared_ptr<TaskHandle>> sortHandles;
        sortHandles.reserve(sortTasks.size());
        
        for (auto& sortTask : sortTasks) {
            if (sortTask.bucket->items.size() >= minItemsForParallel) {
                // ✅ 捕获值而非引用
                auto bucket = sortTask.bucket;
                auto descriptor = sortTask.descriptor;
                
                auto handle = TaskScheduler::GetInstance().SubmitLambda(
                    [bucket, descriptor]() {
                        // ✅ 每个 bucket 的 items 是独立的，不会有竞争
                        SortLayerItems(bucket->items, descriptor);
                    },
                    TaskPriority::High,
                    "LayerSort"
                );
                sortHandles.push_back(handle);
            } else {
                // 小层级直接串行排序
                SortLayerItems(sortTask.bucket->items, sortTask.descriptor);
            }
        }
        
        // 等待所有排序任务完成
        if (!sortHandles.empty()) {
            TaskScheduler::GetInstance().WaitForAll(sortHandles);
        }
    } else {
        // 回退到串行排序
        for (auto& sortTask : sortTasks) {
            SortLayerItems(sortTask.bucket->items, sortTask.descriptor);
        }
    }
    
    // ... 后续代码保持不变 ...
}

// ============================================================================
// 方案2：安全回退到串行实现（保守方案）
// ============================================================================

void Renderer::FlushRenderQueue_SerialFallback() {
    std::vector<LayerBucket> bucketsSnapshot;
    std::vector<RenderLayerRecord> layerRecords;
    uint32_t activeLayerMask = 0;
    size_t pendingCount = 0;
    BatchingMode currentBatchingMode = BatchingMode::Disabled;

    {
        std::lock_guard<std::mutex> lock(m_mutex);
        pendingCount = CountPendingRenderables();
        if (pendingCount == 0) {
            return;
        }

        activeLayerMask = m_activeLayerMask.load();
        currentBatchingMode = m_batchingMode;
        layerRecords = m_layerRegistry.ListLayers();

        bucketsSnapshot = std::move(m_layerBuckets);
        m_layerBuckets.clear();
        m_layerBucketLookup.clear();
        m_submissionCounter = 0;
    }

    // 构建提交顺序
    std::unordered_map<uint32_t, size_t> snapshotLookup;
    snapshotLookup.reserve(bucketsSnapshot.size());
    for (size_t i = 0; i < bucketsSnapshot.size(); ++i) {
        snapshotLookup.emplace(bucketsSnapshot[i].id.value, i);
    }

    std::vector<LayerItem*> submissionOrder;
    submissionOrder.reserve(pendingCount);
    for (auto& bucket : bucketsSnapshot) {
        const bool maskAllows =
            (bucket.maskIndex >= 32) ||
            ((activeLayerMask >> bucket.maskIndex) & 0x1u);
        if (!maskAllows) {
            continue;
        }
        for (auto& item : bucket.items) {
            submissionOrder.push_back(&item);
        }
    }

    std::sort(submissionOrder.begin(), submissionOrder.end(), 
              [](const LayerItem* a, const LayerItem* b) {
        return a->submissionIndex < b->submissionIndex;
    });

    std::vector<Renderable*> originalQueue;
    originalQueue.reserve(submissionOrder.size());
    for (const auto* item : submissionOrder) {
        originalQueue.push_back(item->renderable);
    }

    // ✅ 串行计算材质排序键
    std::unordered_map<uint32_t, std::optional<DepthFunc>> layerDepthFuncMap;
    for (const auto& record : layerRecords) {
        layerDepthFuncMap[record.descriptor.id.value] = record.state.overrides.depthFunc;
    }
    
    for (auto* renderable : originalQueue) {
        if (renderable && renderable->IsMaterialSortKeyDirty()) {
            std::optional<DepthFunc> layerDepthFunc = std::nullopt;
            auto it = layerDepthFuncMap.find(renderable->GetLayerID());
            if (it != layerDepthFuncMap.end()) {
                layerDepthFunc = it->second;
            }
            EnsureMaterialSortKey(renderable, layerDepthFunc);
        }
    }

    const auto originalSwitchMetrics = ComputeMaterialSwitchMetrics(originalQueue);

    std::vector<Renderable*> sortedQueue;
    sortedQueue.reserve(pendingCount);

    std::unordered_map<uint32_t, const RenderLayerRecord*> layerRecordLookup;
    layerRecordLookup.reserve(layerRecords.size());
    for (const auto& record : layerRecords) {
        layerRecordLookup.emplace(record.descriptor.id.value, &record);
    }

    // ✅ 串行排序每个层级
    for (const auto& record : layerRecords) {
        auto lookupIt = snapshotLookup.find(record.descriptor.id.value);
        if (lookupIt == snapshotLookup.end()) {
            continue;
        }

        const size_t bucketIndex = lookupIt->second;
        if (bucketIndex >= bucketsSnapshot.size()) {
            continue;
        }

        LayerBucket& bucket = bucketsSnapshot[bucketIndex];

        if (bucket.items.empty()) {
            continue;
        }

        const bool maskAllows =
            (record.descriptor.maskIndex >= 32) ||
            ((activeLayerMask >> record.descriptor.maskIndex) & 0x1u);

        if (!record.state.enabled || !maskAllows) {
            bucket.items.clear();
            continue;
        }

        // 串行排序
        SortLayerItems(bucket.items, record.descriptor);
        
        ApplyLayerOverrides(record.descriptor, record.state);

        for (const auto& item : bucket.items) {
            if (item.renderable && item.renderable->IsVisible()) {
                sortedQueue.push_back(item.renderable);
            }
        }

        bucket.items.clear();
    }

    // ... 后续批处理逻辑保持不变 ...
}

// ============================================================================
// 方案3：配置开关（推荐用于生产环境）
// ============================================================================

class Renderer {
private:
    std::atomic<bool> m_enableParallelSortKeyCalc{true};
    std::atomic<bool> m_enableParallelLayerSort{true};
    
public:
    void SetParallelSortKeyCalcEnabled(bool enabled) {
        m_enableParallelSortKeyCalc.store(enabled, std::memory_order_relaxed);
    }
    
    void SetParallelLayerSortEnabled(bool enabled) {
        m_enableParallelLayerSort.store(enabled, std::memory_order_relaxed);
    }
    
    bool IsParallelSortKeyCalcEnabled() const {
        return m_enableParallelSortKeyCalc.load(std::memory_order_relaxed);
    }
    
    bool IsParallelLayerSortEnabled() const {
        return m_enableParallelLayerSort.load(std::memory_order_relaxed);
    }
};

void Renderer::FlushRenderQueue_Configurable() {
    // ... 前面的代码保持不变 ...
    
    // 材质排序键计算
    if (IsParallelSortKeyCalcEnabled() && 
        dirtyRenderables.size() >= minDirtyForParallel &&
        TaskScheduler::GetInstance().IsInitialized()) {
        // 使用并行化版本
        ParallelComputeSortKeys(dirtyRenderables, layerDepthFuncMap);
    } else {
        // 使用串行版本
        SerialComputeSortKeys(dirtyRenderables, layerDepthFuncMap);
    }
    
    // 层级排序
    if (IsParallelLayerSortEnabled() && 
        !sortTasks.empty() &&
        TaskScheduler::GetInstance().IsInitialized()) {
        // 使用并行化版本
        ParallelSortLayers(sortTasks);
    } else {
        // 使用串行版本
        SerialSortLayers(sortTasks);
    }
    
    // ... 后续代码保持不变 ...
}
```
## 问题总结与建议

### 主要问题

1. **数据竞争**：多线程同时修改 `Renderable` 对象的状态
2. **引用悬挂**：Lambda 捕获引用可能导致生命周期问题
3. **共享状态**：全局单例（Logger、MaterialStateCache）的线程安全性未知

### 推荐方案（按优先级）

**方案1：修复并行化（推荐用于追求性能）**
- 添加线程安全的 setter/getter
- 使用原子操作和互斥锁保护共享状态
- 捕获值而非引用避免悬挂指针

**方案2：配置开关（推荐用于生产环境）**
- 默认启用并行化，可运行时关闭
- 遇到问题时可快速回退到串行版本
- 方便 A/B 测试和性能对比

**方案3：完全回退到串行（保守方案）**
- 最安全但性能较差
- 适合短期修复或小规模场景

### 实施建议

1. **立即修复**：
   - 在 `Renderable` 类中添加原子变量和互斥锁
   - 修改所有并行代码使用线程安全方法
   - 确保 Lambda 捕获值而非引用

2. **测试验证**：
   - 使用 ThreadSanitizer (TSan) 检测数据竞争
   - 压力测试大量 Renderable 对象场景
   - 对比串行和并行版本的性能

3. **长期优化**：
   - 实现无锁数据结构（如果性能关键）
   - 考虑使用任务图而非简单的并行 for
   - 添加性能监控和回退机制
